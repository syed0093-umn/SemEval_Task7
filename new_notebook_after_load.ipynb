{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrads/syed0093/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade numpy pandas matplotlib sentence-transformers torch tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Iterator\n",
    "import ast\n",
    "import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "our_dataset_path = '/home/csgrads/syed0093/SemEval_Task7/Task_Data/'\n",
    "\n",
    "posts_path = os.path.join(our_dataset_path, 'posts.csv')\n",
    "fact_checks_path = os.path.join(our_dataset_path, 'fact_checks.csv')\n",
    "fact_check_post_mapping_path = os.path.join(our_dataset_path, 'pairs.csv')\n",
    "\n",
    "for path in [posts_path, fact_checks_path, fact_check_post_mapping_path]:\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "parse_col = lambda s: ast.literal_eval(s.replace('\\n', '\\\\n')) if s else s\n",
    "\n",
    "df_fact_checks = pd.read_csv(fact_checks_path).fillna('').set_index('fact_check_id')\n",
    "for col in ['claim', 'instances', 'title']:\n",
    "    df_fact_checks[col] = df_fact_checks[col].apply(parse_col)\n",
    "\n",
    "\n",
    "df_posts = pd.read_csv(posts_path).fillna('').set_index('post_id')\n",
    "for col in ['instances', 'ocr', 'verdicts', 'text']:\n",
    "    df_posts[col] = df_posts[col].apply(parse_col)\n",
    "\n",
    "\n",
    "df_fact_check_post_mapping = pd.read_csv(fact_check_post_mapping_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the filtered DataFrame to a new CSV file\n",
    "# df_fact_checks.to_csv('processed_fact_checks.csv', index=False)\n",
    "# df_fact_checks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instances</th>\n",
       "      <th>ocr</th>\n",
       "      <th>verdicts</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(1608571882.0, fb)]</td>\n",
       "      <td>[(! Dreister Impf-Fake von Markus Söder! Es is...</td>\n",
       "      <td>[False information]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(1586139153.0, fb)]</td>\n",
       "      <td>[(!! WARNING !! A new thing circulating now. P...</td>\n",
       "      <td>[False information]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(1610052141.0, fb), (1610072448.0, fb)]</td>\n",
       "      <td>[(\"Actually, he's a damn sight better than any...</td>\n",
       "      <td>[Missing context]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(1645187790.0, ig)]</td>\n",
       "      <td>[(\"Australia 50 MILLONES de dosis de \"vacuna\" ...</td>\n",
       "      <td>[False]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(1581697500.0, fb)]</td>\n",
       "      <td>[(\"Bienaventurados los perseguidos por mi caus...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        instances  \\\n",
       "post_id                                             \n",
       "0                            [(1608571882.0, fb)]   \n",
       "1                            [(1586139153.0, fb)]   \n",
       "2        [(1610052141.0, fb), (1610072448.0, fb)]   \n",
       "3                            [(1645187790.0, ig)]   \n",
       "4                            [(1581697500.0, fb)]   \n",
       "\n",
       "                                                       ocr  \\\n",
       "post_id                                                      \n",
       "0        [(! Dreister Impf-Fake von Markus Söder! Es is...   \n",
       "1        [(!! WARNING !! A new thing circulating now. P...   \n",
       "2        [(\"Actually, he's a damn sight better than any...   \n",
       "3        [(\"Australia 50 MILLONES de dosis de \"vacuna\" ...   \n",
       "4        [(\"Bienaventurados los perseguidos por mi caus...   \n",
       "\n",
       "                    verdicts text  \n",
       "post_id                            \n",
       "0        [False information]       \n",
       "1        [False information]       \n",
       "2          [Missing context]       \n",
       "3                    [False]       \n",
       "4                         []       "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_posts.to_csv('processed_posts.csv', index=False)\n",
    "# df_posts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>fact_check_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2228</td>\n",
       "      <td>23568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2228</td>\n",
       "      <td>194577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2229</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2229</td>\n",
       "      <td>23568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  fact_check_id\n",
       "0     2228             33\n",
       "1     2228          23568\n",
       "2     2228         194577\n",
       "3     2229             33\n",
       "4     2229          23568"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_fact_check_post_mapping.to_csv('processed_pairs.csv', index=False)\n",
    "# df_fact_check_post_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def parse_text_tuple(text_str):\n",
    "    \"\"\"Parse the tuple string format and extract text content.\"\"\"\n",
    "    try:\n",
    "        # Convert string representation of tuple to actual tuple\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple) and len(data) >= 2:\n",
    "            # Return both original and translated text if available\n",
    "            return ' '.join([str(data[0]), str(data[1])])\n",
    "        return str(data[0])\n",
    "    except:\n",
    "        return text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instances(instances_str):\n",
    "    \"\"\"Parse the instances string to extract URLs and timestamps.\"\"\"\n",
    "    try:\n",
    "        data = ast.literal_eval(instances_str)\n",
    "        return [item[1] if isinstance(item, tuple) and len(item) > 1 else str(item) \n",
    "                for item in data]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_post(row):\n",
    "    \"\"\"Combine relevant text fields from a post.\"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    # Process text field\n",
    "    if pd.notna(row.get('text')):\n",
    "        try:\n",
    "            text_data = ast.literal_eval(row['text'])\n",
    "            if isinstance(text_data, list):\n",
    "                for item in text_data:\n",
    "                    if isinstance(item, tuple) and len(item) > 0:\n",
    "                        texts.append(str(item[0]))  # Original text\n",
    "            else:\n",
    "                texts.append(str(text_data))\n",
    "        except:\n",
    "            texts.append(str(row['text']))\n",
    "    \n",
    "    return ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieval_system(fact_checks_df, posts_df, task_config, language):\n",
    "    \"\"\"Create and train the retrieval system for a specific language.\"\"\"\n",
    "    # Filter fact checks for the specified language\n",
    "    valid_fact_check_ids = task_config['monolingual'][language]['fact_checks']\n",
    "    fact_checks = fact_checks_df[fact_checks_df['fact_check_id'].isin(valid_fact_check_ids)]\n",
    "    \n",
    "    # Prepare fact check texts\n",
    "    fact_check_texts = []\n",
    "    for _, row in fact_checks.iterrows():\n",
    "        texts = []\n",
    "        if pd.notna(row['claim']):\n",
    "            texts.append(parse_text_tuple(row['claim']))\n",
    "        if pd.notna(row['title']):\n",
    "            texts.append(parse_text_tuple(row['title']))\n",
    "        fact_check_texts.append(' '.join(texts))\n",
    "    \n",
    "    # Create TF-IDF vectors for fact checks\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    fact_check_vectors = vectorizer.fit_transform(fact_check_texts)\n",
    "    \n",
    "    return vectorizer, fact_check_vectors, fact_checks['fact_check_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_fact_checks(post_text, vectorizer, fact_check_vectors, fact_check_ids, top_k=10):\n",
    "    \"\"\"Retrieve the most relevant fact checks for a given post.\"\"\"\n",
    "    post_vector = vectorizer.transform([post_text])\n",
    "    similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return [fact_check_ids[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(posts_df, task_config, vectorizer, fact_check_vectors, \n",
    "                        fact_check_ids, language, split='posts_dev'):\n",
    "    \"\"\"Generate predictions for the development set.\"\"\"\n",
    "    predictions = {}\n",
    "    valid_post_ids = task_config['monolingual'][language][split]\n",
    "    \n",
    "    for post_id in valid_post_ids:\n",
    "        post = posts_df[posts_df['post_id'] == post_id].iloc[0]\n",
    "        post_text = preprocess_post(post)\n",
    "        retrieved_fact_checks = retrieve_fact_checks(\n",
    "            post_text, vectorizer, fact_check_vectors, fact_check_ids\n",
    "        )\n",
    "        predictions[str(post_id)] = retrieved_fact_checks\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    # Process for each language\n",
    "    all_predictions = {}\n",
    "    for language in tasks['monolingual'].keys():\n",
    "        vectorizer, fact_check_vectors, fact_check_ids = create_retrieval_system(\n",
    "            fact_checks, posts, tasks, language\n",
    "        )\n",
    "        \n",
    "        predictions = generate_predictions(\n",
    "            posts, tasks, vectorizer, fact_check_vectors, fact_check_ids, language\n",
    "        )\n",
    "        all_predictions.update(predictions)\n",
    "    \n",
    "    # Save predictions\n",
    "    with open('monolingual_predictions_tfidf.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BERTRetriever:\n",
    "    def __init__(self, model_name='xlm-roberta-base', max_length=512):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        embeddings = []\n",
    "        \n",
    "        for text in tqdm(texts, desc=\"Generating embeddings\"):\n",
    "            encoded = self.tokenizer(text, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=self.max_length, \n",
    "                                   return_tensors='pt')\n",
    "            \n",
    "            encoded = {k: v.to(self.device) for k, v in encoded.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_output = self.model(**encoded)\n",
    "            \n",
    "            sentence_embedding = self.mean_pooling(model_output, encoded['attention_mask'])\n",
    "            embeddings.append(sentence_embedding.cpu().numpy()[0])\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def parse_text_tuple(text_str):\n",
    "    try:\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple) and len(data) >= 2:\n",
    "            return ' '.join([str(data[0]), str(data[1])])\n",
    "        return str(data[0])\n",
    "    except:\n",
    "        return text_str\n",
    "\n",
    "def create_retrieval_system(fact_checks_df, posts_df, task_config, language):\n",
    "    retriever = BERTRetriever()\n",
    "    \n",
    "    # Filter fact checks\n",
    "    valid_fact_check_ids = task_config['monolingual'][language]['fact_checks']\n",
    "    fact_checks = fact_checks_df[fact_checks_df['fact_check_id'].isin(valid_fact_check_ids)]\n",
    "    \n",
    "    # Prepare fact check texts\n",
    "    fact_check_texts = []\n",
    "    for _, row in fact_checks.iterrows():\n",
    "        texts = []\n",
    "        if pd.notna(row['claim']):\n",
    "            texts.append(parse_text_tuple(row['claim']))\n",
    "        if pd.notna(row['title']):\n",
    "            texts.append(parse_text_tuple(row['title']))\n",
    "        fact_check_texts.append(' '.join(texts))\n",
    "    \n",
    "    # Generate embeddings\n",
    "    fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "    \n",
    "    return retriever, fact_check_vectors, fact_checks['fact_check_id'].tolist()\n",
    "\n",
    "def retrieve_fact_checks(post_text, retriever, fact_check_vectors, fact_check_ids, top_k=10):\n",
    "    post_vector = retriever.get_embeddings([post_text])\n",
    "    similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return [fact_check_ids[i] for i in top_indices]\n",
    "\n",
    "def preprocess_post(row):\n",
    "    texts = []\n",
    "    if pd.notna(row.get('text')):\n",
    "        try:\n",
    "            text_data = ast.literal_eval(row['text'])\n",
    "            if isinstance(text_data, list):\n",
    "                for item in text_data:\n",
    "                    if isinstance(item, tuple) and len(item) > 0:\n",
    "                        texts.append(str(item[0]))\n",
    "            else:\n",
    "                texts.append(str(text_data))\n",
    "        except:\n",
    "            texts.append(str(row['text']))\n",
    "    return ' '.join(texts)\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing language: {language}\")\n",
    "        \n",
    "        retriever, fact_check_vectors, fact_check_ids = create_retrieval_system(\n",
    "            fact_checks, posts, tasks, language\n",
    "        )\n",
    "        \n",
    "        valid_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        for post_id in tqdm(valid_post_ids, desc=\"Generating predictions\"):\n",
    "            post = posts[posts['post_id'] == post_id].iloc[0]\n",
    "            post_text = preprocess_post(post)\n",
    "            retrieved_fact_checks = retrieve_fact_checks(\n",
    "                post_text, retriever, fact_check_vectors, fact_check_ids\n",
    "            )\n",
    "            all_predictions[str(post_id)] = retrieved_fact_checks\n",
    "    \n",
    "    # Save predictions\n",
    "    with open('monolingual_predictions_bert_1.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Processing fra\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:03, 52.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing spa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [00:21, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing eng\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478it [01:10,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing por\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:14, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing tha\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 109.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing deu\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:01, 55.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing msa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:02, 46.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ara\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:02, 28.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions...\n"
     ]
    }
   ],
   "source": [
    "class BERTRetriever:\n",
    "    def __init__(self, model_name='xlm-roberta-base'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        embeddings = []\n",
    "        batch_size = 8\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            encoded = self.tokenizer(batch, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=512, \n",
    "                                   return_tensors='pt')\n",
    "            \n",
    "            encoded = {k: v.to(self.device) for k, v in encoded.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "                # Use CLS token embedding\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def process_text(text_str):\n",
    "    if pd.isna(text_str):\n",
    "        return \"\"\n",
    "    try:\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple):\n",
    "            return str(data[0])  # Use original text\n",
    "        elif isinstance(data, list):\n",
    "            return ' '.join(str(item[0]) if isinstance(item, tuple) else str(item) for item in data)\n",
    "        return str(data)\n",
    "    except:\n",
    "        return str(text_str)\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    pairs = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/pairs.csv')  # Load gold pairs\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    retriever = BERTRetriever()\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Prepare fact check texts\n",
    "        fact_check_texts = []\n",
    "        for _, row in language_fact_checks.iterrows():\n",
    "            text = process_text(row['claim']) + \" \" + process_text(row['title'])\n",
    "            fact_check_texts.append(text)\n",
    "        \n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_text(post['text'])\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions with correct ID type\n",
    "            all_predictions[str(int(post['post_id']))] = [str(fact_check_ids[i]) for i in top_indices]\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    with open('monolingual_predictions_bert_2.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infloat E5 multilingual large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fra: 188it [00:03, 60.03it/s]\n",
      "Processing spa: 615it [00:09, 64.46it/s]\n",
      "Processing eng: 478it [00:10, 46.29it/s]\n",
      "Processing por: 302it [00:04, 63.50it/s]\n",
      "Processing tha: 42it [00:00, 46.30it/s]\n",
      "Processing deu: 83it [00:01, 56.72it/s]\n",
      "Processing msa: 105it [00:01, 65.34it/s]\n",
      "Processing ara: 78it [00:01, 62.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class E5Retriever:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "        self.model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(self.device)\n",
    "    \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    \n",
    "    def get_embeddings(self, texts, batch_size=8):\n",
    "        embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_dict = self.tokenizer(batch, max_length=512, padding=True, \n",
    "                                      truncation=True, return_tensors='pt')\n",
    "            batch_dict = {k: v.to(self.device) for k, v in batch_dict.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch_dict)\n",
    "            emb = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "            embeddings.extend(F.normalize(emb, p=2, dim=1).cpu().numpy())\n",
    "            \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def format_text(row, type='fact_check'):\n",
    "    if type == 'fact_check':\n",
    "        claim = row.get('claim', '')\n",
    "        title = row.get('title', '')\n",
    "        return f\"passage: {claim} {title}\"\n",
    "    else:\n",
    "        return f\"query: {row.get('text', '')}\"\n",
    "\n",
    "def main():\n",
    "    retriever = E5Retriever()\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        fact_check_texts = [format_text(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        for _, post in tqdm(dev_posts.iterrows(), desc=f\"Processing {language}\"):\n",
    "            post_text = format_text(post, type='post')\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            scores = (post_vector @ fact_check_vectors.T)[0]\n",
    "            top_indices = np.argsort(scores)[-10:][::-1]\n",
    "            \n",
    "            predictions[str(int(post['post_id']))] = [str(fact_check_ids[i]) for i in top_indices]\n",
    "    \n",
    "    with open('monolingual_predictions_e5_large.json', 'w') as f:\n",
    "        json.dump(predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 22 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASTTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.3-cp310-cp310-linux_x86_64.whl\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/lib/python3/dist-packages (from fasttext) (59.6.0)\n",
      "Requirement already satisfied: numpy in /home/csgrads/syed0093/.local/lib/python3.10/site-packages (from fasttext) (1.24.3)\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
     ]
    }
   ],
   "source": [
    "! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText retriever...\n",
      "Loading datasets...\n",
      "\n",
      "Processing fra\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:00, 215.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing spa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [00:08, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing eng\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478it [00:31, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing por\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:03, 85.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing tha\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 475.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing deu\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:00, 181.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing msa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:00, 114.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ara\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:00, 93.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions...\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "\n",
    "class FastTextRetriever:\n",
    "    def __init__(self, model_name='cc.en.300.bin'):\n",
    "        \"\"\"Initialize FastText retriever with specified model.\"\"\"\n",
    "        # Download model if not exists\n",
    "        if not os.path.exists(model_name):\n",
    "            fasttext.util.download_model('en', if_exists='ignore')\n",
    "        self.model = fasttext.load_model(model_name)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text.lower()\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Get FastText embedding for a single text.\"\"\"\n",
    "        text = self.preprocess_text(text)\n",
    "        if not text:\n",
    "            return np.zeros(self.model.get_dimension())\n",
    "        return self.model.get_sentence_vector(text)\n",
    "    \n",
    "    def get_embeddings(self, texts, batch_size=32):\n",
    "        \"\"\"Get FastText embeddings for a batch of texts.\"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_embeddings = [self.get_embedding(text) for text in batch]\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "def process_fact_check(row):\n",
    "    \"\"\"Process fact check text from row.\"\"\"\n",
    "    try:\n",
    "        claim = str(row.get('claim', ''))\n",
    "        title = str(row.get('title', ''))\n",
    "        return f\"{claim} {title}\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_post(row):\n",
    "    \"\"\"Process post text from row.\"\"\"\n",
    "    try:\n",
    "        return str(row.get('text', ''))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    print(\"Loading FastText retriever...\")\n",
    "    retriever = FastTextRetriever()\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Get fact check embeddings\n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_texts = [process_fact_check(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_post(post)\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions\n",
    "            post_id = str(int(post['post_id']))\n",
    "            predictions = [str(fact_check_ids[i]) for i in top_indices]\n",
    "            all_predictions[post_id] = predictions\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    os.makedirs('predictions', exist_ok=True)\n",
    "    with open('monolingual_predictions_fasttext.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GTR-T5 retriever...\n",
      "Loading datasets...\n",
      "\n",
      "Processing fra\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:06, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing spa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [00:23, 25.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing eng\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478it [01:19,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing por\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:14, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing tha\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:01, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing deu\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:02, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing msa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:03, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ara\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:02, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class GTRRetriever:\n",
    "    def __init__(self, model_name='sentence-transformers/gtr-t5-large'):\n",
    "        \"\"\"Initialize GTR-T5 retriever with specified model.\"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text.lower()\n",
    "    \n",
    "    def get_embedding(self, text):\n",
    "        \"\"\"Get GTR-T5 embedding for a single text.\"\"\"\n",
    "        text = self.preprocess_text(text)\n",
    "        if not text:\n",
    "            return np.zeros(768)  # GTR-T5-Large has 768 dimensions\n",
    "        return self.model.encode(text)\n",
    "    \n",
    "    def get_embeddings(self, texts, batch_size=32):\n",
    "        \"\"\"Get GTR-T5 embeddings for a batch of texts.\"\"\"\n",
    "        # Clean texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "        # Replace empty texts with a space to avoid errors\n",
    "        processed_texts = [text if text else \" \" for text in processed_texts]\n",
    "        # Use model's built-in batching\n",
    "        return self.model.encode(processed_texts, batch_size=batch_size)\n",
    "\n",
    "def process_fact_check(row):\n",
    "    \"\"\"Process fact check text from row.\"\"\"\n",
    "    try:\n",
    "        claim = str(row.get('claim', ''))\n",
    "        title = str(row.get('title', ''))\n",
    "        return f\"{claim} {title}\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_post(row):\n",
    "    \"\"\"Process post text from row.\"\"\"\n",
    "    try:\n",
    "        return str(row.get('text', ''))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    print(\"Loading GTR-T5 retriever...\")\n",
    "    retriever = GTRRetriever()\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Get fact check embeddings\n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_texts = [process_fact_check(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_post(post)\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions\n",
    "            post_id = str(int(post['post_id']))\n",
    "            predictions = [str(fact_check_ids[i]) for i in top_indices]\n",
    "            all_predictions[post_id] = predictions\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    os.makedirs('predictions', exist_ok=True)\n",
    "    with open('predictions/monolingual_predictions_gtr.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 19 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class DistilBERTRetriever:\n",
    "    def __init__(self, model_name='distilbert-base-nli-stsb-mean-tokens'):\n",
    "        \"\"\"Initialize DistilBERT retriever with specified model.\"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        # Convert to string\n",
    "        text = str(text)\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text.lower()\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    \n",
    "    def get_embeddings(self, texts, batch_size=32):\n",
    "        \"\"\"Get DistilBERT embeddings for a batch of texts.\"\"\"\n",
    "        # Clean texts\n",
    "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
    "        # Replace empty texts with a space to avoid errors\n",
    "        processed_texts = [text if text else \" \" for text in processed_texts]\n",
    "        # Use model's built-in batching with show_progress_bar\n",
    "        return self.model.encode(processed_texts, batch_size=batch_size, show_progress_bar=True)\n",
    "\n",
    "def process_fact_check(row):\n",
    "    \"\"\"Process fact check text from row.\"\"\"\n",
    "    try:\n",
    "        claim = str(row.get('claim', ''))\n",
    "        title = str(row.get('title', ''))\n",
    "        return f\"{claim} {title}\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_post(row):\n",
    "    \"\"\"Process post text from row.\"\"\"\n",
    "    try:\n",
    "        return str(row.get('text', ''))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    print(\"Loading DistilBERT retriever...\")\n",
    "    retriever = DistilBERTRetriever()\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Get fact check embeddings\n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_texts = [process_fact_check(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_post(post)\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions\n",
    "            post_id = str(int(post['post_id']))\n",
    "            predictions = [str(fact_check_ids[i]) for i in top_indices]\n",
    "            all_predictions[post_id] = predictions\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    os.makedirs('predictions', exist_ok=True)\n",
    "    with open('predictions/monolingual_predictions_distilBERT.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "# Runtime: 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrads/syed0093/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fra\n",
      "Generating fact check embeddings...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "class EnhancedRetriever:\n",
    "    def __init__(self):\n",
    "        # Bi-encoder for initial retrieval\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('microsoft/mdeberta-v3-base')\n",
    "        self.model = AutoModel.from_pretrained('microsoft/mdeberta-v3-base')\n",
    "        # Cross-encoder for reranking\n",
    "        self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    def get_embeddings(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    \n",
    "    def rerank(self, query, candidates):\n",
    "        pairs = [[query, candidate] for candidate in candidates]\n",
    "        scores = self.cross_encoder.predict(pairs)\n",
    "        return scores\n",
    "\n",
    "def process_fact_check(row):\n",
    "    \"\"\"Process fact check text from row.\"\"\"\n",
    "    try:\n",
    "        claim = str(row.get('claim', ''))\n",
    "        title = str(row.get('title', ''))\n",
    "        return f\"{claim} {title}\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_post(row):\n",
    "    \"\"\"Process post text from row.\"\"\"\n",
    "    try:\n",
    "        return str(row.get('text', ''))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    retriever = EnhancedRetriever()\n",
    "    # ...existing code...\n",
    "    # After getting top_indices:\n",
    "    print(\"Loading datasets...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Get fact check embeddings\n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_texts = [process_fact_check(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_post(post)\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions\n",
    "            post_id = str(int(post['post_id']))\n",
    "            reranked_scores = retriever.rerank(post_text, [fact_checks.iloc[i] for i in top_indices])\n",
    "            final_indices = top_indices[np.argsort(reranked_scores)[::-1]]\n",
    "            predictions = [str(fact_check_ids[i]) for i in final_indices]\n",
    "            all_predictions[post_id] = predictions\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    os.makedirs('predictions', exist_ok=True)\n",
    "    with open('predictions/monolingual_predictions_enhanced_retriever.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

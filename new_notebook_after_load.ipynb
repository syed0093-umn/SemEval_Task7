{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrads/syed0093/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade numpy pandas matplotlib sentence-transformers torch tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Iterator\n",
    "import ast\n",
    "import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "our_dataset_path = '/home/csgrads/syed0093/SemEval_Task7/Task_Data/'\n",
    "\n",
    "posts_path = os.path.join(our_dataset_path, 'posts.csv')\n",
    "fact_checks_path = os.path.join(our_dataset_path, 'fact_checks.csv')\n",
    "fact_check_post_mapping_path = os.path.join(our_dataset_path, 'pairs.csv')\n",
    "\n",
    "for path in [posts_path, fact_checks_path, fact_check_post_mapping_path]:\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    \n",
    "parse_col = lambda s: ast.literal_eval(s.replace('\\n', '\\\\n')) if s else s\n",
    "\n",
    "df_fact_checks = pd.read_csv(fact_checks_path).fillna('').set_index('fact_check_id')\n",
    "for col in ['claim', 'instances', 'title']:\n",
    "    df_fact_checks[col] = df_fact_checks[col].apply(parse_col)\n",
    "\n",
    "\n",
    "df_posts = pd.read_csv(posts_path).fillna('').set_index('post_id')\n",
    "for col in ['instances', 'ocr', 'verdicts', 'text']:\n",
    "    df_posts[col] = df_posts[col].apply(parse_col)\n",
    "\n",
    "\n",
    "df_fact_check_post_mapping = pd.read_csv(fact_check_post_mapping_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>instances</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fact_check_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( Are avocados good for you?,  Are avocados go...</td>\n",
       "      <td>[(1525653998.0, https://metafact.io/factchecks...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>( Can animals have headaches?,  Can animals ha...</td>\n",
       "      <td>[(1617955634.0, https://metafact.io/factchecks...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( Can we help prevent Alzheimer's with diet?, ...</td>\n",
       "      <td>[(1525653998.0, https://metafact.io/factchecks...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( Do any benefits of alcohol outweigh the risk...</td>\n",
       "      <td>[(1525653998.0, https://metafact.io/factchecks...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>( Does acupuncture work for headaches?,  Does ...</td>\n",
       "      <td>[(1617955595.0, https://metafact.io/factchecks...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           claim  \\\n",
       "fact_check_id                                                      \n",
       "0              ( Are avocados good for you?,  Are avocados go...   \n",
       "1              ( Can animals have headaches?,  Can animals ha...   \n",
       "2              ( Can we help prevent Alzheimer's with diet?, ...   \n",
       "3              ( Do any benefits of alcohol outweigh the risk...   \n",
       "4              ( Does acupuncture work for headaches?,  Does ...   \n",
       "\n",
       "                                                       instances title  \n",
       "fact_check_id                                                           \n",
       "0              [(1525653998.0, https://metafact.io/factchecks...        \n",
       "1              [(1617955634.0, https://metafact.io/factchecks...        \n",
       "2              [(1525653998.0, https://metafact.io/factchecks...        \n",
       "3              [(1525653998.0, https://metafact.io/factchecks...        \n",
       "4              [(1617955595.0, https://metafact.io/factchecks...        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Save the filtered DataFrame to a new CSV file\n",
    "# df_fact_checks.to_csv('processed_fact_checks.csv', index=False)\n",
    "# df_fact_checks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instances</th>\n",
       "      <th>ocr</th>\n",
       "      <th>verdicts</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(1608571882.0, fb)]</td>\n",
       "      <td>[(! Dreister Impf-Fake von Markus Söder! Es is...</td>\n",
       "      <td>[False information]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(1586139153.0, fb)]</td>\n",
       "      <td>[(!! WARNING !! A new thing circulating now. P...</td>\n",
       "      <td>[False information]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(1610052141.0, fb), (1610072448.0, fb)]</td>\n",
       "      <td>[(\"Actually, he's a damn sight better than any...</td>\n",
       "      <td>[Missing context]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(1645187790.0, ig)]</td>\n",
       "      <td>[(\"Australia 50 MILLONES de dosis de \"vacuna\" ...</td>\n",
       "      <td>[False]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(1581697500.0, fb)]</td>\n",
       "      <td>[(\"Bienaventurados los perseguidos por mi caus...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        instances  \\\n",
       "post_id                                             \n",
       "0                            [(1608571882.0, fb)]   \n",
       "1                            [(1586139153.0, fb)]   \n",
       "2        [(1610052141.0, fb), (1610072448.0, fb)]   \n",
       "3                            [(1645187790.0, ig)]   \n",
       "4                            [(1581697500.0, fb)]   \n",
       "\n",
       "                                                       ocr  \\\n",
       "post_id                                                      \n",
       "0        [(! Dreister Impf-Fake von Markus Söder! Es is...   \n",
       "1        [(!! WARNING !! A new thing circulating now. P...   \n",
       "2        [(\"Actually, he's a damn sight better than any...   \n",
       "3        [(\"Australia 50 MILLONES de dosis de \"vacuna\" ...   \n",
       "4        [(\"Bienaventurados los perseguidos por mi caus...   \n",
       "\n",
       "                    verdicts text  \n",
       "post_id                            \n",
       "0        [False information]       \n",
       "1        [False information]       \n",
       "2          [Missing context]       \n",
       "3                    [False]       \n",
       "4                         []       "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_posts.to_csv('processed_posts.csv', index=False)\n",
    "# df_posts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>fact_check_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2228</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2228</td>\n",
       "      <td>23568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2228</td>\n",
       "      <td>194577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2229</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2229</td>\n",
       "      <td>23568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  fact_check_id\n",
       "0     2228             33\n",
       "1     2228          23568\n",
       "2     2228         194577\n",
       "3     2229             33\n",
       "4     2229          23568"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_fact_check_post_mapping.to_csv('processed_pairs.csv', index=False)\n",
    "# df_fact_check_post_mapping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def parse_text_tuple(text_str):\n",
    "    \"\"\"Parse the tuple string format and extract text content.\"\"\"\n",
    "    try:\n",
    "        # Convert string representation of tuple to actual tuple\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple) and len(data) >= 2:\n",
    "            # Return both original and translated text if available\n",
    "            return ' '.join([str(data[0]), str(data[1])])\n",
    "        return str(data[0])\n",
    "    except:\n",
    "        return text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instances(instances_str):\n",
    "    \"\"\"Parse the instances string to extract URLs and timestamps.\"\"\"\n",
    "    try:\n",
    "        data = ast.literal_eval(instances_str)\n",
    "        return [item[1] if isinstance(item, tuple) and len(item) > 1 else str(item) \n",
    "                for item in data]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_post(row):\n",
    "    \"\"\"Combine relevant text fields from a post.\"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    # Process text field\n",
    "    if pd.notna(row.get('text')):\n",
    "        try:\n",
    "            text_data = ast.literal_eval(row['text'])\n",
    "            if isinstance(text_data, list):\n",
    "                for item in text_data:\n",
    "                    if isinstance(item, tuple) and len(item) > 0:\n",
    "                        texts.append(str(item[0]))  # Original text\n",
    "            else:\n",
    "                texts.append(str(text_data))\n",
    "        except:\n",
    "            texts.append(str(row['text']))\n",
    "    \n",
    "    return ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieval_system(fact_checks_df, posts_df, task_config, language):\n",
    "    \"\"\"Create and train the retrieval system for a specific language.\"\"\"\n",
    "    # Filter fact checks for the specified language\n",
    "    valid_fact_check_ids = task_config['monolingual'][language]['fact_checks']\n",
    "    fact_checks = fact_checks_df[fact_checks_df['fact_check_id'].isin(valid_fact_check_ids)]\n",
    "    \n",
    "    # Prepare fact check texts\n",
    "    fact_check_texts = []\n",
    "    for _, row in fact_checks.iterrows():\n",
    "        texts = []\n",
    "        if pd.notna(row['claim']):\n",
    "            texts.append(parse_text_tuple(row['claim']))\n",
    "        if pd.notna(row['title']):\n",
    "            texts.append(parse_text_tuple(row['title']))\n",
    "        fact_check_texts.append(' '.join(texts))\n",
    "    \n",
    "    # Create TF-IDF vectors for fact checks\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    fact_check_vectors = vectorizer.fit_transform(fact_check_texts)\n",
    "    \n",
    "    return vectorizer, fact_check_vectors, fact_checks['fact_check_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_fact_checks(post_text, vectorizer, fact_check_vectors, fact_check_ids, top_k=10):\n",
    "    \"\"\"Retrieve the most relevant fact checks for a given post.\"\"\"\n",
    "    post_vector = vectorizer.transform([post_text])\n",
    "    similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return [fact_check_ids[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(posts_df, task_config, vectorizer, fact_check_vectors, \n",
    "                        fact_check_ids, language, split='posts_dev'):\n",
    "    \"\"\"Generate predictions for the development set.\"\"\"\n",
    "    predictions = {}\n",
    "    valid_post_ids = task_config['monolingual'][language][split]\n",
    "    \n",
    "    for post_id in valid_post_ids:\n",
    "        post = posts_df[posts_df['post_id'] == post_id].iloc[0]\n",
    "        post_text = preprocess_post(post)\n",
    "        retrieved_fact_checks = retrieve_fact_checks(\n",
    "            post_text, vectorizer, fact_check_vectors, fact_check_ids\n",
    "        )\n",
    "        predictions[str(post_id)] = retrieved_fact_checks\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    # Process for each language\n",
    "    all_predictions = {}\n",
    "    for language in tasks['monolingual'].keys():\n",
    "        vectorizer, fact_check_vectors, fact_check_ids = create_retrieval_system(\n",
    "            fact_checks, posts, tasks, language\n",
    "        )\n",
    "        \n",
    "        predictions = generate_predictions(\n",
    "            posts, tasks, vectorizer, fact_check_vectors, fact_check_ids, language\n",
    "        )\n",
    "        all_predictions.update(predictions)\n",
    "    \n",
    "    # Save predictions\n",
    "    with open('monolingual_predictions_tfidf.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing language: fra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 4355/4355 [00:24<00:00, 175.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.29it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.30it/s]s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.57it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 134.78it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.20it/s]s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.35it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 123.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.67it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.70it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 103.17it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 88.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.14it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 126.18it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.26it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 126.99it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.39it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 85.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.79it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 126.84it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 118.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 137.14it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.45it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.09it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.41it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 117.35it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 86.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 115.88it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.07it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.98it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.29it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.29it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.03it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.17it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.52it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.51it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.73it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 59.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 38.97it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.12it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 104.68it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 99.87it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.81it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.08it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 104.36it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 40.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 58.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 121.38it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 118.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 119.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 101.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 99.95it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 101.27it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.31it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 161.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.66it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.84it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 102.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 114.03it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.96it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 137.12it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.55it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 113.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 161.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 50.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.29it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 94.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.09it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.32it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.12it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 112.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.84it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 137.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.89it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 58.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.79it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 103.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 114.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 102.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 162.53it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.19it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.61it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 160.38it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.18it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.51it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.46it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.86it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 91.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.32it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.93it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.30it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 114.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.77it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.86it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.79it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 42.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 112.98it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 113.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.17it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 113.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 95.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.76it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 102.39it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 50.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.12it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 163.26it/s]\n",
      "Generating predictions: 100%|██████████| 188/188 [00:04<00:00, 41.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing language: spa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 14082/14082 [01:18<00:00, 178.76it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.90it/s]s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.28it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.83it/s]s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.18it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 159.80it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.12it/s]s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.87it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.83it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.77it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.15it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.09it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.19it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.76it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.30it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.07it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.95it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.77it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.51it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 134.32it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.17it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.37it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.07it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.15it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.02it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.01it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.02it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.86it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.77it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 33.78it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.71it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 64.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.08it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.01it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 123.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 45.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 48.88it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.11it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.64it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 84.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 105.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.45it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.08it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.10it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.61it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 105.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 41.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 97.07it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.26it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.46it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.81it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 97.39it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.27it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 46.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 43.26it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 45.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.67it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.74it/s]/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.52it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.43it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.00it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 88.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.53it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.98it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 97.78it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.93it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.13it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.19it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.41it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.51it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.26it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.66it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.42it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.32it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.17it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.90it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.32it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.99it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 95.46it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.30it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.87it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.10it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.64it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 64.07it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.42it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.97it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 64.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 50.68it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.19it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 99.73it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 35.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.21it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.38it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.16it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.67it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.76it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.71it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 62.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.61it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 50.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.32it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.29it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.25it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.04it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 92.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 44.35it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.92it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 92.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.17it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.32it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.99it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.77it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 87.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.30it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.03it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.97it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 134.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.43it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.65it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 102.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.23it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 32.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.96it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.33it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 50.99it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.53it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.07it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.07it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 91.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.03it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.28it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.28it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 41.46it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.17it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.56it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.48it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 41.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.18it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.06it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.65it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 100.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.90it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.16it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 88.12it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.83it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.40it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.12it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.77it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 49.29it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.00it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 100.51it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.81it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 37.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 101.09it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.10it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.31it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.76it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.84it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.86it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.81it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.43it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.46it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.43it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 95.38it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.41it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.31it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.66it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.78it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.28it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.94it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.46it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.73it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.02it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.25it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.78it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.68it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 87.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.58it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.08it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.46it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.75it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.38it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.19it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.07it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.19it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.31it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.50it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.32it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.83it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 92.92it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.51it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.77it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.27it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 134.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.97it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 45.75it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 132.16it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.70it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.86it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.86it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 112.29it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 56.76it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.65it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 115.70it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.09it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.10it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.64it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.70it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.20it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 130.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.37it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 56.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.10it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.76it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.96it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.79it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 91.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 100.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.44it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 133.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.12it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.96it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.05it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.95it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 46.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.15it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.84it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.75it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.43it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 158.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.76it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.80it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.72it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.59it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 88.84it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.62it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.68it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.86it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 99.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 157.27it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.92it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.41it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.43it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 156.00it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 56.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.48it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.15it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 90.96it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.18it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 112.38it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.42it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.62it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.12it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 86.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 110.79it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 93.66it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 45.28it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 109.99it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.66it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.93it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.44it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.74it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.58it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.49it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.80it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.47it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.16it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 86.25it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.63it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.07it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.73it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.34it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.54it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.16it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.69it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.93it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.36it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.40it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.17it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.24it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 135.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.99it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.32it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.95it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 123.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.68it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.41it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.11it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 138.10it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.81it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.30it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.82it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.70it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.91it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 92.72it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 94.37it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 137.42it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.82it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.03it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 141.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.53it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.91it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.06it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 106.64it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 92.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.57it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.45it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.09it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 123.56it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.13it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.02it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.18it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.38it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.28it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 148.58it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 97.14it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.43it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.85it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.95it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 105.45it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 105.41it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 124.03it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.96it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.26it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 47.87it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 47.91it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 155.14it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 154.47it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 139.41it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 152.14it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 144.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 104.59it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 46.39it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.11it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 147.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.73it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 104.09it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.90it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 131.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 96.36it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.42it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 87.01it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 94.40it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.36it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 136.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.13it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 105.22it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.83it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 108.21it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.60it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.65it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 63.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 140.46it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.89it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 85.10it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.19it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 153.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.52it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 151.47it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 125.82it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 150.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 111.63it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 115.62it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 145.48it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 51.46it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 142.64it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 44.60it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 98.20it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 126.49it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 88.93it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 127.88it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 137.95it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 107.68it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 149.66it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 46.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 129.19it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 43.14it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.54it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 48.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.35it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 89.45it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 126.27it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 122.55it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 143.45it/s]t/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 87.77it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 128.49it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 54.40it/s]it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 146.11it/s]\n",
      "Generating predictions: 100%|██████████| 615/615 [00:23<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing language: eng\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BERTRetriever:\n",
    "    def __init__(self, model_name='xlm-roberta-base', max_length=512):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        embeddings = []\n",
    "        \n",
    "        for text in tqdm(texts, desc=\"Generating embeddings\"):\n",
    "            encoded = self.tokenizer(text, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=self.max_length, \n",
    "                                   return_tensors='pt')\n",
    "            \n",
    "            encoded = {k: v.to(self.device) for k, v in encoded.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_output = self.model(**encoded)\n",
    "            \n",
    "            sentence_embedding = self.mean_pooling(model_output, encoded['attention_mask'])\n",
    "            embeddings.append(sentence_embedding.cpu().numpy()[0])\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def parse_text_tuple(text_str):\n",
    "    try:\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple) and len(data) >= 2:\n",
    "            return ' '.join([str(data[0]), str(data[1])])\n",
    "        return str(data[0])\n",
    "    except:\n",
    "        return text_str\n",
    "\n",
    "def create_retrieval_system(fact_checks_df, posts_df, task_config, language):\n",
    "    retriever = BERTRetriever()\n",
    "    \n",
    "    # Filter fact checks\n",
    "    valid_fact_check_ids = task_config['monolingual'][language]['fact_checks']\n",
    "    fact_checks = fact_checks_df[fact_checks_df['fact_check_id'].isin(valid_fact_check_ids)]\n",
    "    \n",
    "    # Prepare fact check texts\n",
    "    fact_check_texts = []\n",
    "    for _, row in fact_checks.iterrows():\n",
    "        texts = []\n",
    "        if pd.notna(row['claim']):\n",
    "            texts.append(parse_text_tuple(row['claim']))\n",
    "        if pd.notna(row['title']):\n",
    "            texts.append(parse_text_tuple(row['title']))\n",
    "        fact_check_texts.append(' '.join(texts))\n",
    "    \n",
    "    # Generate embeddings\n",
    "    fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "    \n",
    "    return retriever, fact_check_vectors, fact_checks['fact_check_id'].tolist()\n",
    "\n",
    "def retrieve_fact_checks(post_text, retriever, fact_check_vectors, fact_check_ids, top_k=10):\n",
    "    post_vector = retriever.get_embeddings([post_text])\n",
    "    similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return [fact_check_ids[i] for i in top_indices]\n",
    "\n",
    "def preprocess_post(row):\n",
    "    texts = []\n",
    "    if pd.notna(row.get('text')):\n",
    "        try:\n",
    "            text_data = ast.literal_eval(row['text'])\n",
    "            if isinstance(text_data, list):\n",
    "                for item in text_data:\n",
    "                    if isinstance(item, tuple) and len(item) > 0:\n",
    "                        texts.append(str(item[0]))\n",
    "            else:\n",
    "                texts.append(str(text_data))\n",
    "        except:\n",
    "            texts.append(str(row['text']))\n",
    "    return ' '.join(texts)\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    all_predictions = {}\n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing language: {language}\")\n",
    "        \n",
    "        retriever, fact_check_vectors, fact_check_ids = create_retrieval_system(\n",
    "            fact_checks, posts, tasks, language\n",
    "        )\n",
    "        \n",
    "        valid_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        for post_id in tqdm(valid_post_ids, desc=\"Generating predictions\"):\n",
    "            post = posts[posts['post_id'] == post_id].iloc[0]\n",
    "            post_text = preprocess_post(post)\n",
    "            retrieved_fact_checks = retrieve_fact_checks(\n",
    "                post_text, retriever, fact_check_vectors, fact_check_ids\n",
    "            )\n",
    "            all_predictions[str(post_id)] = retrieved_fact_checks\n",
    "    \n",
    "    # Save predictions\n",
    "    with open('monolingual_predictions_bert_1.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Processing fra\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [00:03, 52.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing spa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [00:26, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing eng\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478it [01:09,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing por\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [00:14, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing tha\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:00, 112.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing deu\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:01, 58.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing msa\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [00:01, 53.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ara\n",
      "Generating fact check embeddings...\n",
      "Processing posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:03, 23.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions...\n"
     ]
    }
   ],
   "source": [
    "class BERTRetriever:\n",
    "    def __init__(self, model_name='xlm-roberta-base'):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        embeddings = []\n",
    "        batch_size = 8\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            encoded = self.tokenizer(batch, \n",
    "                                   padding=True, \n",
    "                                   truncation=True, \n",
    "                                   max_length=512, \n",
    "                                   return_tensors='pt')\n",
    "            \n",
    "            encoded = {k: v.to(self.device) for k, v in encoded.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "                # Use CLS token embedding\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def process_text(text_str):\n",
    "    if pd.isna(text_str):\n",
    "        return \"\"\n",
    "    try:\n",
    "        data = ast.literal_eval(text_str)\n",
    "        if isinstance(data, tuple):\n",
    "            return str(data[0])  # Use original text\n",
    "        elif isinstance(data, list):\n",
    "            return ' '.join(str(item[0]) if isinstance(item, tuple) else str(item) for item in data)\n",
    "        return str(data)\n",
    "    except:\n",
    "        return str(text_str)\n",
    "\n",
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    pairs = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/pairs.csv')  # Load gold pairs\n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    retriever = BERTRetriever()\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        print(f\"\\nProcessing {language}\")\n",
    "        \n",
    "        # Filter fact checks for language\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        # Prepare fact check texts\n",
    "        fact_check_texts = []\n",
    "        for _, row in language_fact_checks.iterrows():\n",
    "            text = process_text(row['claim']) + \" \" + process_text(row['title'])\n",
    "            fact_check_texts.append(text)\n",
    "        \n",
    "        print(\"Generating fact check embeddings...\")\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        # Process dev posts\n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        print(\"Processing posts...\")\n",
    "        for _, post in tqdm(dev_posts.iterrows()):\n",
    "            post_text = process_text(post['text'])\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            # Calculate similarities and get top matches\n",
    "            similarities = cosine_similarity(post_vector, fact_check_vectors).flatten()\n",
    "            top_indices = np.argsort(similarities)[-10:][::-1]\n",
    "            \n",
    "            # Store predictions with correct ID type\n",
    "            all_predictions[str(int(post['post_id']))] = [str(fact_check_ids[i]) for i in top_indices]\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    with open('monolingual_predictions_bert_2.json', 'w') as f:\n",
    "        json.dump(all_predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infloat E5 multilingual large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198bf42f8c1c4c1e9b878330cad39312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cf706bc9784de393585702fa5119b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ab8b6ee96e4f8584092fa3e6b6c77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13717e0f08747ea9a87a41adc545f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02154da898914041854c735db345a216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172fdcaea61e4a3bb577e73bb7606a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fra: 188it [00:03, 62.36it/s]\n",
      "Processing spa: 615it [00:09, 64.79it/s]\n",
      "Processing eng: 478it [00:10, 46.87it/s]\n",
      "Processing por: 302it [00:05, 60.31it/s]\n",
      "Processing tha: 42it [00:00, 45.68it/s]\n",
      "Processing deu: 83it [00:01, 62.60it/s]\n",
      "Processing msa: 105it [00:01, 59.09it/s]\n",
      "Processing ara: 78it [00:01, 72.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class E5Retriever:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "        self.model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(self.device)\n",
    "    \n",
    "    def average_pool(self, last_hidden_states, attention_mask):\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    \n",
    "    def get_embeddings(self, texts, batch_size=8):\n",
    "        embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_dict = self.tokenizer(batch, max_length=512, padding=True, \n",
    "                                      truncation=True, return_tensors='pt')\n",
    "            batch_dict = {k: v.to(self.device) for k, v in batch_dict.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch_dict)\n",
    "            emb = self.average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "            embeddings.extend(F.normalize(emb, p=2, dim=1).cpu().numpy())\n",
    "            \n",
    "        return np.array(embeddings)\n",
    "\n",
    "def format_text(row, type='fact_check'):\n",
    "    if type == 'fact_check':\n",
    "        claim = row.get('claim', '')\n",
    "        title = row.get('title', '')\n",
    "        return f\"passage: {claim} {title}\"\n",
    "    else:\n",
    "        return f\"query: {row.get('text', '')}\"\n",
    "\n",
    "def main():\n",
    "    retriever = E5Retriever()\n",
    "    fact_checks = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/fact_checks.csv')\n",
    "    posts = pd.read_csv('/home/csgrads/syed0093/SemEval_Task7/Task_Data/posts.csv')\n",
    "    \n",
    "    with open('tasks.json') as f:\n",
    "        tasks = json.load(f)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for language in tasks['monolingual'].keys():\n",
    "        valid_fact_checks = tasks['monolingual'][language]['fact_checks']\n",
    "        language_fact_checks = fact_checks[fact_checks['fact_check_id'].isin(valid_fact_checks)]\n",
    "        \n",
    "        fact_check_texts = [format_text(row) for _, row in language_fact_checks.iterrows()]\n",
    "        fact_check_vectors = retriever.get_embeddings(fact_check_texts)\n",
    "        fact_check_ids = language_fact_checks['fact_check_id'].tolist()\n",
    "        \n",
    "        dev_post_ids = tasks['monolingual'][language]['posts_dev']\n",
    "        dev_posts = posts[posts['post_id'].isin(dev_post_ids)]\n",
    "        \n",
    "        for _, post in tqdm(dev_posts.iterrows(), desc=f\"Processing {language}\"):\n",
    "            post_text = format_text(post, type='post')\n",
    "            post_vector = retriever.get_embeddings([post_text])\n",
    "            \n",
    "            scores = (post_vector @ fact_check_vectors.T)[0]\n",
    "            top_indices = np.argsort(scores)[-10:][::-1]\n",
    "            \n",
    "            predictions[str(int(post['post_id']))] = [str(fact_check_ids[i]) for i in top_indices]\n",
    "    \n",
    "    with open('monolingual_predictions_e5_large.json', 'w') as f:\n",
    "        json.dump(predictions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
